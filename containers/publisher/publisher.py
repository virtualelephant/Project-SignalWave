import pika
import time
import random
import os
import logging
import json

from faker import Faker
from urllib.parse import urlparse
from prometheus_client import start_http_server, Counter, Summary

# Configure structured logging
class JsonFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": self.formatTime(record),
            "level": record.levelname,
            "message": record.getMessage(),
            "service": "publisher-service",
        }
        return json.dumps(log_record)

logger = logging.getLogger()
handler = logging.StreamHandler()
handler.setFormatter(JsonFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

RABBITMQ_HOST = os.getenv('RABBITMQ_HOST', 'rabbitmq.signalwave.svc.cluster.local')
#RABBITMQ_PORT = int(os.getenv('RABBITMQ_PORT', 5672))
RABBITMQ_USER = os.getenv('RABBITMQ_USER', 'deploy')
RABBITMQ_PASS = os.getenv('RABBITMQ_PASS', 'VMware123!')
QUEUE_NAME = os.getenv('RABBITMQ_QUEUE', 'signalwave')
MESSAGE_RATE = float(os.getenv('MESSAGE_RATE', 1.0)) # Messages per second

rabbitmq_port_env = os.getenv('RABBITMQ_PORT', '5672')
if rabbitmq_port_env.startswith('tcp://'):
    RABBITMQ_PORT = int(urlparse(rabbitmq_port_env).port)
else:
    RABBITMQ_PORT = int(rabbitmq_port_env)

credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)

# Prometheus Metrics
messages_published = Counter('publisher_messages_total', 'Total messages published')
publish_duration = Summary('publisher_publish_duration_seconds', 'Time spent publishing messages')

logger.info("Exposing Prometheus metrics to be scraped by an external server")

try:
    # Establish connection to RabbitMQ
    connection = pika.BlockingConnection(pika.ConnectionParameters(host=RABBITMQ_HOST, port=RABBITMQ_PORT, credentials=credentials))
    channel = connection.channel()
    channel.queue_declare(queue=QUEUE_NAME, durable=True, arguments={"x-queue-type": "quorum"})
    logger.info("Successfully connected to RabbitMQ and declared queue")

    # Message Generator
    fake = Faker()
    log_levels = ['INFO', 'DEBUG', 'WARN', 'ERROR']

    def generate_message():
        level = random.choice(log_levels)
        message = f"{level}: [Generated by Publisher] {fake.sentence()}"
        return {
            "level": level,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime()),
            "message": message
        }

    max_messages = 10
    message_count = 0

    logger.info(f"Starting message publisher at {MESSAGE_RATE} messages per second")
    while message_count < max_messages:
        msg = generate_message()
        body = json.dumps(msg)
        channel.basic_publish(exchange='', routing_key=QUEUE_NAME, body=body)
        logger.info({"action": "publish", "message": msg})
        message_count += 1
        messages_published.inc()
        time.sleep(1 / MESSAGE_RATE)

except KeyboardInterrupt:
    logger.info("Shutting down publisher...")
except Exception as e:
    logger.error({"error": str(e)})
finally:
    if 'connection' in locals() and connection.is_open:
        connection.close()
        logger.info("Connection to RabbitMQ closed")
