Skip to content
Chat history

You said:
Has the fluentd containers been moved? Getting this error when installing fluentd through helm off of the bitnami Helm chart repo:

Failed to pull image "docker.io/bitnami/fluentd:1.19.0-debian-12-r1": rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/bitnami/fluentd:1.19.0-debian-12-r1": failed to resolve image: docker.io/bitnami/fluentd:1.19.0-debian-12-r1: not found
ChatGPT said:

Thought for 27s
Yep — this is a Bitnami catalog change, not you. Bitnami removed most versioned images from docker.io/bitnami/* on Aug 28, 2025. Many tags (like bitnami/fluentd:1.19.0-debian-12-r1) were pulled from the free catalog, with “frozen” copies moved to the bitnamilegacy org; only a small, “latest”-only set remains in bitnamisecure. That’s why your Helm pull is 404’ing. 
GitHub
+2
GitHub
+2

Quick fixes (pick one)
Point the chart at the legacy image (short-term band-aid)

You’ll get the old tag back, but it won’t get updates.

# values override
helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace logging --create-namespace \
  --set image.repository=docker.io/bitnamilegacy/fluentd \
  --set image.tag=1.19.0-debian-12-r1
Legacy images are explicitly for temporary fallback and receive no fixes. 
Docker Hub
+1

Switch to the upstream Fluentd image (recommended free option)
Use the official Fluentd image instead of Bitnami:

helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace logging --create-namespace \
  --set image.repository=docker.io/fluent/fluentd \
  --set image.tag=edge-debian
(Choose a specific upstream tag if you need pinning.) 
Docker Hub
+1

Mirror to your Harbor (best for stability in your lab)
Pull the upstream (or legacy) image once, push to Harbor, and point the chart there:

# on a workstation that can pull
docker pull fluent/fluentd:edge-debian
docker tag fluent/fluentd:edge-debian harbor.home.virtualelephant.com/ve-lab/fluentd:edge-debian
docker push harbor.home.virtualelephant.com/ve-lab/fluentd:edge-debian

# then deploy
helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace logging --create-namespace \
  --set image.repository=harbor.home.virtualelephant.com/ve-lab/fluentd \
  --set image.tag=edge-debian
Why this happened
Broadcom/Bitnami changed distribution: most Debian-based, versioned images were removed from the free Docker Hub org (bitnami/*). Older tags were moved to bitnamilegacy/*; ongoing, only a slim “latest” set is free under bitnamisecure/*. Charts are still published, but you must override the image repository/tag now. 
GitHub
+1

If you want, tell me which path you prefer (legacy vs upstream vs Harbor mirror), and I’ll hand you a tiny values.yaml that fits your current Bitnami chart and your Harbor trust chain.

You said:
I want to use option 2, but I also have a values file 'fluentd-values.yaml' that I want to make sure is used
ChatGPT said:

Thought for 16s
Great—let’s keep your existing fluentd-values.yaml and layer a tiny override on top to switch to the upstream image and fix security context paths.

1) Create a small overlay file
Save as fluentd-image-override.yaml (separate from your main values):

image:
  repository: docker.io/fluent/fluentd
  # pick a tag you want; "v1.16-debian-1" is a stable upstream tag.
  # you can also use "edge-debian" if you really want the latest.
  tag: v1.16-debian-1
  pullPolicy: IfNotPresent

# Bitnami chart defaults to non-root 1001; upstream fluentd image runs as root.
# Override so the container can start.
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# Point Fluentd to the config path used by the upstream image.
# (Bitnami image used /opt/bitnami/fluentd/conf; upstream uses /fluentd/etc)
extraEnvVars:
  - name: FLUENTD_CONF
    value: fluent.conf
  - name: FLUENTD_OPT
    value: ""
If your main fluentd-values.yaml sets any volumeMounts or paths under /opt/bitnami/fluentd, change those to upstream defaults (/fluentd/etc for config, /fluentd/log for logs).

2) Install/upgrade with both files
helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace logging --create-namespace \
  -f fluentd-values.yaml \
  -f fluentd-image-override.yaml
Notes you may care about
Plugins: Bitnami’s image often bundled extras. The upstream image is slimmer.
If your config needs plugins (e.g., fluent-plugin-elasticsearch, fluent-plugin-prometheus), the cleanest path is to build a tiny derived image that installs them:

FROM fluent/fluentd:v1.16-debian-1
RUN gem install --no-document fluent-plugin-elasticsearch fluent-plugin-prometheus
Push that to Harbor and change image.repository/tag accordingly. (I can hand you that Dockerfile + a Harbor push script if you want.)

Security / root: If your environment requires non-root, we can switch to a non-root UID and pre-create writable dirs in a custom image. With the stock upstream image, running as root is the simplest.

Paths: Upstream defaults:

Config: /fluentd/etc/fluent.conf

Logs: /fluentd/log

Buffer dirs: make sure any buffer paths in your values match mounted volumes under /fluentd.

If you paste your current fluentd-values.yaml, I’ll adjust any paths/plugins so the upstream image works 1:1.

You said:
Unrecognized images:
  - docker.io/docker.io/fluent/fluentd:v1.16-debian-1
ChatGPT said:

Thought for 12s
You’re seeing that because Bitnami charts split the image into registry and repository.
You set repository: docker.io/fluent/fluentd while the chart still has registry: docker.io, so it concatenated to docker.io/docker.io/fluent/fluentd.

Fix = keep the registry separate and make the repository just fluent/fluentd.

Update your overlay to this
image:
  registry: docker.io
  repository: fluent/fluentd
  tag: v1.16-debian-1      # or use "edge-debian" if you prefer latest
  pullPolicy: IfNotPresent

containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

extraEnvVars:
  - name: FLUENTD_CONF
    value: fluent.conf
  - name: FLUENTD_OPT
    value: ""
Apply with both files
helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace logging --create-namespace \
  -f fluentd-values.yaml \
  -f fluentd-image-override.yaml
If your fluentd-values.yaml references Bitnami-specific paths (e.g., /opt/bitnami/fluentd/...), switch them to upstream defaults:

config: /fluentd/etc/fluent.conf

logs/buffers: under /fluentd/

Paste your values if you want me to align any mounts/paths or plugin installs for the upstream image.

You said:
deploy@c1-blade01:~$ helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd   --namespace services --create-namespace   -f fluentd-values.yaml   -f fluentd-image-override.yaml
Pulled: registry-1.docker.io/bitnamicharts/fluentd:7.2.5
Digest: sha256:3475bc5053a1c9d60840e108625680c7f566228abc74a5485db8c1020c9e6b5a
Error: UPGRADE FAILED: execution error at (fluentd/templates/NOTES.txt:62:4): 

⚠ ERROR: Original containers have been substituted for unrecognized ones. Deploying this chart with non-standard containers is likely to cause degraded security and performance, broken chart features, and missing environment variables.

Unrecognized images:
  - docker.io/fluent/fluentd:edge-debian

If you are sure you want to proceed with non-standard containers, you can skip container image verification by setting the global parameter 'global.security.allowInsecureImages' to true.
Further information can be obtained at https://github.com/bitnami/charts/issues/30850
ChatGPT said:
That error is the Bitnami “image verification” guard. Since we’re intentionally swapping in the upstream fluent/fluentd image, you need to tell the chart to allow non-Bitnami images.

Add this to your override file and re-apply:

# fluentd-image-override.yaml

global:
  security:
    allowInsecureImages: true   # <-- lets you use non-Bitnami images

image:
  registry: docker.io
  repository: fluent/fluentd
  tag: edge-debian              # or a pinned tag like v1.16-debian-1
  pullPolicy: IfNotPresent

# Upstream image runs as root by default
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# Point to upstream config location/entry
extraEnvVars:
  - name: FLUENTD_CONF
    value: fluent.conf
  - name: FLUENTD_OPT
    value: ""

# (Optional) If your main values mounted config under /opt/bitnami/..., 
# switch those mounts/paths to /fluentd/etc and buffers under /fluentd/.
Then install/upgrade using both files:

helm upgrade --install fluentd oci://registry-1.docker.io/bitnamicharts/fluentd \
  --namespace services --create-namespace \
  -f fluentd-values.yaml \
  -f fluentd-image-override.yaml
If anything in fluentd-values.yaml references Bitnami paths (/opt/bitnami/fluentd/...), change to upstream defaults:

config dir → /fluentd/etc (main file /fluentd/etc/fluent.conf)

logs/buffers → somewhere under /fluentd/… (e.g., /fluentd/buffer, /fluentd/log)

If you want, paste your fluentd-values.yaml and I’ll tweak mounts/paths or plugin installs so the upstream image runs cleanly.

You said:
okay, how about we start fresh with fluentd and you show me how to install it from helm using whatever the upstream packages with any Helm repo you recommend
ChatGPT said:

Thought for 27s
Perfect—let’s switch to Fluent’s upstream Helm repo and use their charts (no Bitnami involved).

Option A — Plain Fluentd chart (simple & familiar)
Add the upstream repo and refresh:

helm repo add fluent https://fluent.github.io/helm-charts
helm repo update
GitHub

Create a minimal fluentd-values.yaml (DaemonSet that tails /var/log/containers and forwards to Elasticsearch—adjust the ES host/creds/CA to your environment):

image:
  registry: docker.io
  repository: fluent/fluentd
  tag: v1.16-debian-1
  pullPolicy: IfNotPresent

rbac:
  create: true

serviceAccount:
  create: true
  name: fluentd

# Run as root (upstream image default) so it can read container logs on nodes
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# Mount the container logs directory
volumes:
  - name: varlog
    hostPath:
      path: /var/log/containers
      type: Directory
volumeMounts:
  - name: varlog
    mountPath: /var/log/containers
    readOnly: true

# Fluentd config: input from Kubernetes container logs, output to Elasticsearch
# NOTE: Update hosts/ssl/creds to match your ELK.
configFile: |-
  <source>
    @type tail
    @id in_kube_logs
    path /var/log/containers/*.log
    pos_file /fluentd/log/k8s-containers.pos
    tag kube.*
    <parse>
      @type regexp
      expression /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    </parse>
    read_from_head true
    refresh_interval 5
    rotate_wait 5
    multiline_flush_interval 5
  </source>

  # Add Kubernetes metadata (optional but recommended)
  <filter kube.**>
    @type kubernetes_metadata
    @id filter_kube_metadata
    skip_labels false
    skip_container_metadata false
    skip_namespace_metadata false
    skip_master_url true
  </filter>

  # Send to Elasticsearch
  <match kube.**>
    @type elasticsearch
    @id out_es
    host elasticsearch-master.elasticsearch.svc   # <-- change if yours differs
    port 9200
    scheme https                                   # http or https
    ssl_verify true                                # set false if you don’t have CA
    ca_file /fluentd/etc/es-ca.crt                 # mount your CA below, or remove
    logstash_format true
    include_tag_key true
    reconnect_on_error true
    reload_connections true
    request_timeout 60s
    user elastic                                   # <-- if you use basic auth
    password changeme                              # <-- replace
    index_name kubernetes-%Y.%m.%d
  </match>

# Optional: mount your ES CA cert if using TLS + custom CA
extraVolumes:
  - name: es-ca
    secret:
      secretName: es-ca-secret   # kubectl create secret generic es-ca-secret --from-file=es-ca.crt=</path/to/ca.crt> -n services
extraVolumeMounts:
  - name: es-ca
    mountPath: /fluentd/etc
    readOnly: true

resources:
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi
Install it (I’ll keep your services namespace):

helm upgrade --install fluentd fluent/fluentd \
  --namespace services --create-namespace \
  -f fluentd-values.yaml
Docs confirming the official repo & images: upstream Helm repo (fluent.github.io/helm-charts) and Fluentd container defaults (/fluentd/etc/fluent.conf). 
GitHub
+2
Fluentd
+2

Option B — Fluent Operator (Kubernetes-native, CRDs, manages Fluentd & Fluent Bit)
If you’d like a more scalable/“Kubernetes way” to manage pipelines, install Fluent Operator once, then declare inputs/filters/outputs with CRDs.

Install operator:

helm repo add fluent https://fluent.github.io/helm-charts
helm repo update
helm upgrade --install fluent-operator fluent/fluent-operator \
  --namespace logging --create-namespace
GitHub
+1

Example CRDs (cluster-wide Fluentd that tails container logs and ships to Elasticsearch):

# logging/fluentd.yaml
apiVersion: fluentd.fluent.io/v1alpha1
kind: ClusterFluentd
metadata:
  name: default
spec:
  globalInputs:
    - http: {} # example built-in input; real log input comes from ClusterInput below
  replicas: 1  # or DaemonSet via DaemonSetFluentd in the same API group

---
apiVersion: fluentbit.fluent.io/v1alpha2
kind: ClusterInput
metadata:
  name: k8s-containers
spec:
  tail:
    tag: kube.*
    path: /var/log/containers/*.log

---
apiVersion: fluentd.fluent.io/v1alpha1
kind: ClusterOutput
metadata:
  name: es
spec:
  elasticsearch:
    host: elasticsearch-master.elasticsearch.svc
    port: 9200
    scheme: https
    sslVerify: true
    # secretRef for user/password or CA can be added here
Operator + CRDs are documented in Fluent’s repos and on Artifact Hub. 
GitHub
+1

Which should you pick?
Option A (plain chart): fastest path and closest to what you were doing—good for a single cluster and simple routing.

Option B (operator): best if you expect multiple pipelines, dynamic outputs per namespace, or want to manage Fluentd/Bit via CRDs.

If you tell me your Elasticsearch service name, TLS/CA details, and whether you need non-root, I’ll tailor the values (or CRDs) exactly to your lab.

You said:
Please combine your values.yaml file with the custom values I have for my kubernetes cluster:

fullnameOverride: fluentd
namespaceOverride: services

daemonset:
  enabled: true

elasticsearch:
  enabled: true
  host: elasticsearch-master
  port: 9200
  scheme: https

persistence:
  enabled: true
  storageClass: lonhorn-retain
  accessModes:
    - ReadWriteOnce
  size: 5Gi

rbac:
  create: true

serviceMonitor:
  enabled: true
  namespace: services
  interval: 30s
  scrapeTimeout: 10s
  endpoints:
    - port: metrics
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

output a single fluentd-values.yaml file for this new upstream Helm repo
ChatGPT said:

Thought for 41s
Here’s a single fluentd-values.yaml tailored for the upstream chart (fluent/fluentd repo) and merged with your cluster-specific prefs. I also wired in metrics and Elasticsearch, and added a small initContainer that installs the needed plugins at runtime (Elasticsearch, Prometheus, and Kubernetes metadata).

Note: you had storageClass: lonhorn-retain; I corrected the typo to longhorn-retain. Also, PVCs with a DaemonSet depend on how the chart handles persistence; this file uses the chart’s persistence knob with a buffer path under /fluentd/buffer. If your storage class is ReadWriteOnce (typical), each pod will bind its own PVC—supported by the upstream chart.

# === names / placement ===
fullnameOverride: fluentd
namespaceOverride: services

# Deploy as a DaemonSet on every node
daemonset:
  enabled: true

# === image ===
image:
  registry: docker.io
  repository: fluent/fluentd
  tag: v1.16-debian-1
  pullPolicy: IfNotPresent

rbac:
  create: true

serviceAccount:
  create: true
  name: fluentd

# === security context ===
# Upstream fluent/fluentd runs as root by default; this keeps things simple
# for accessing /var/log/containers. We can harden to non-root later if desired.
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# === volumes for log tailing & plugin install cache ===
volumes:
  - name: varlog
    hostPath:
      path: /var/log/containers
      type: Directory
  - name: gem-cache
    emptyDir: {}

volumeMounts:
  - name: varlog
    mountPath: /var/log/containers
    readOnly: true
  - name: gem-cache
    mountPath: /opt/fluentd/plugins

# Install required plugins (ES output, Prometheus metrics, K8s metadata) at startup.
# We install them into /opt/fluentd/plugins (shared emptyDir), and add that directory
# to Ruby's load path via FLUENTD_OPT below.
extraInitContainers:
  - name: install-fluentd-plugins
    image: docker.io/fluent/fluentd:v1.16-debian-1
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh","-c"]
    args:
      - >
        gem install --no-document
        fluent-plugin-elasticsearch
        fluent-plugin-prometheus
        fluent-plugin-kubernetes_metadata_filter
        --install-dir /opt/fluentd/plugins;
        echo "Installed plugins to /opt/fluentd/plugins";
    volumeMounts:
      - name: gem-cache
        mountPath: /opt/fluentd/plugins

# Ensure fluentd loads plugins from /opt/fluentd/plugins
extraEnvVars:
  - name: FLUENTD_CONF
    value: fluent.conf
  - name: FLUENTD_OPT
    value: "-I /opt/fluentd/plugins"

# === persistence for buffers ===
# Uses a PVC per pod for buffering (recommended)
persistence:
  enabled: true
  # corrected typo "longhorn-retain"
  storageClass: longhorn-retain
  accessModes:
    - ReadWriteOnce
  size: 5Gi
  # Where to mount the buffer volume inside the container
  mountPath: /fluentd/buffer

# === service & metrics ===
service:
  type: ClusterIP
  ports:
    - name: metrics
      port: 24231
      targetPort: 24231

# Prometheus Operator ServiceMonitor (uses your settings)
serviceMonitor:
  enabled: true
  namespace: services
  interval: 30s
  scrapeTimeout: 10s
  endpoints:
    - port: metrics
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s

# === resources ===
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# === Elasticsearch connection (used by config below) ===
# (Kept your structure for clarity—even though the upstream chart doesn't
# auto-wire this, we reference these values in the configFile.)
elasticsearch:
  enabled: true
  host: elasticsearch-master
  port: 9200
  scheme: https
  # If you need basic auth or a custom CA, mount a secret and add:
  # user: elastic
  # password: "changeme"
  # caFile: /fluentd/etc/es-ca.crt

# === Fluentd configuration ===
# - Tails Kubernetes container logs
# - Adds Kubernetes metadata
# - Exposes Prometheus metrics at :24231/metrics
# - Outputs to Elasticsearch with logstash-style index naming
configFile: |-
  # --- Inputs: tail Kubernetes container logs ---
  <source>
    @type tail
    @id in_kube_logs
    path /var/log/containers/*.log
    pos_file /fluentd/log/k8s-containers.pos
    tag kube.*
    <parse>
      @type regexp
      expression /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    </parse>
    read_from_head true
    refresh_interval 5
    rotate_wait 5
    multiline_flush_interval 5
  </source>

  # --- Kubernetes metadata enrichment ---
  <filter kube.**>
    @type kubernetes_metadata
    @id filter_kube_metadata
    skip_labels false
    skip_container_metadata false
    skip_namespace_metadata false
    skip_master_url true
  </filter>

  # --- Prometheus metrics endpoint (:24231/metrics) ---
  <source>
    @type prometheus
    bind 0.0.0.0
    port 24231
  </source>
  <source>
    @type prometheus_monitor
  </source>

  # --- Elasticsearch output ---
  <match kube.**>
    @type elasticsearch
    @id out_es
    host ${elasticsearch_host}
    port ${elasticsearch_port}
    scheme ${elasticsearch_scheme}
    logstash_format true
    include_tag_key true
    reconnect_on_error true
    reload_connections true
    request_timeout 60s
    # If you mount a CA cert:
    # ssl_verify true
    # ca_file ${elasticsearch_ca_file}
    # If you use basic auth:
    # user ${elasticsearch_user}
    # password ${elasticsearch_password}

    # Buffer to the PVC
    <buffer>
      @type file
      path /fluentd/buffer/es
      flush_interval 5s
      retry_max_interval 30
      chunk_limit_size 8m
      flush_thread_count 2
    </buffer>
  </match>

# Wire config to values via env (so you can tweak host/port/scheme without editing the config block)
extraEnvVarsCM: ""
extraEnvVarsSecret: ""
extraEnvVars:
  - name: elasticsearch_host
    value: "{{ .Values.elasticsearch.host }}"
  - name: elasticsearch_port
    value: "{{ .Values.elasticsearch.port | toString }}"
  - name: elasticsearch_scheme
    value: "{{ .Values.elasticsearch.scheme }}"
  # Uncomment if you add these to .Values.elasticsearch and mount their files/secrets
  # - name: elasticsearch_user
  #   value: "{{ .Values.elasticsearch.user }}"
  # - name: elasticsearch_password
  #   valueFrom:
  #     secretKeyRef:
  #       name: es-basic-auth
  #       key: password
  # - name: elasticsearch_ca_file
  #   value: "{{ .Values.elasticsearch.caFile }}"

# If you need to mount a CA for Elasticsearch TLS, provide a secret and uncomment:
# extraVolumes:
#   - name: es-ca
#     secret:
#       secretName: es-ca-secret
# extraVolumeMounts:
#   - name: es-ca
#     mountPath: /fluentd/etc
#     readOnly: true
Install command (upstream repo)
helm repo add fluent https://fluent.github.io/helm-charts
helm repo update

helm upgrade --install fluentd fluent/fluentd \
  --namespace services --create-namespace \
  -f fluentd-values.yaml
If you want me to switch this to non-root hardening, or to use a Harbor-hosted custom image with plugins pre-baked (cleaner, faster starts), I can produce that Dockerfile + updated values too.

You said:
deploy@c1-blade01:~/git/Project-SignalWave/core-services/ELK$ helm upgrade --install fluentd fluent/fluentd --namespace services -f fluentd-values.yaml
Release "fluentd" does not exist. Installing it now.
Error: 2 errors occurred:
        * Service "fluentd" is invalid: [spec.ports[1].name: Duplicate value: "metrics", spec.ports[1].port: Invalid value: 0: must be between 1 and 65535, inclusive, spec.ports[1].targetPort: Invalid value: 0: must be between 1 and 65535, inclusive]
        * DaemonSet.apps "fluentd" is invalid: [spec.template.spec.volumes[4].name: Duplicate value: "varlog", spec.template.spec.containers[0].ports[1].name: Duplicate value: "metrics", spec.template.spec.containers[0].ports[1].containerPort: Required value, spec.template.spec.containers[0].volumeMounts[6].name: Not found: "fluentd-buffer"]
ChatGPT said:

Thought for 56s
# --- Names / placement ---
fullnameOverride: fluentd
namespaceOverride: services

daemonset:
  enabled: true

# --- Image ---
image:
  registry: docker.io
  repository: fluent/fluentd
  tag: v1.16-debian-1
  pullPolicy: IfNotPresent

rbac:
  create: true

serviceAccount:
  create: true
  name: fluentd

# --- Security context ---
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# --- Host log mounts (chart-managed flags to avoid duplicate volumes) ---
mountVarLogDirectory: true            # mounts /var/log
mountDockerContainersDirectory: true  # mounts /var/lib/docker/containers if present

# --- Install needed plugins on startup (chart supports this) ---
plugins:
  - fluent-plugin-elasticsearch
  - fluent-plugin-prometheus
  - fluent-plugin-kubernetes_metadata_filter

# --- Persistence for buffers (PVC per DaemonSet pod) ---
persistence:
  enabled: true
  storageClass: longhorn-retain
  accessModes:
    - ReadWriteOnce
  size: 5Gi

# --- Metrics service & ServiceMonitor (chart creates a Service on :24231) ---
metrics:
  serviceMonitor:
    enabled: true
    namespace: services
    interval: 30s
    scrapeTimeout: 10s
    endpoints:
      - port: metrics
        path: /metrics
        interval: 15s
        scrapeTimeout: 10s

# --- Resources ---
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# --- Elasticsearch connection (referenced by config below) ---
elasticsearch:
  enabled: true
  host: elasticsearch-master
  port: 9200
  scheme: https
  # If you need auth/CA later, add keys here (user/password/caFile) and mount secrets.

# --- Fluentd configuration ---
# - Tails Kubernetes container logs from node
# - Adds Kubernetes metadata
# - Exposes Prometheus metrics at :24231/metrics
# - Outputs to Elasticsearch with logstash-style indices
configFile: |-
  # Inputs: tail Kubernetes container logs
  <source>
    @type tail
    @id in_kube_logs
    path /var/log/containers/*.log
    pos_file /fluentd/log/k8s-containers.pos
    tag kube.*
    <parse>
      @type regexp
      expression /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    </parse>
    read_from_head true
    refresh_interval 5
    rotate_wait 5
    multiline_flush_interval 5
  </source>

  # Kubernetes metadata enrichment
  <filter kube.**>
    @type kubernetes_metadata
    @id filter_kube_metadata
    skip_labels false
    skip_container_metadata false
    skip_namespace_metadata false
    skip_master_url true
  </filter>

  # Prometheus metrics endpoint (:24231/metrics)
  <source>
    @type prometheus
    bind 0.0.0.0
    port 24231
  </source>
  <source>
    @type prometheus_monitor
  </source>

  # Elasticsearch output
  <match kube.**>
    @type elasticsearch
    @id out_es
    host ${elasticsearch_host}
    port ${elasticsearch_port}
    scheme ${elasticsearch_scheme}
    logstash_format true
    include_tag_key true
    reconnect_on_error true
    reload_connections true
    request_timeout 60s

    # Buffer to PVC-backed storage (chart mounts persistence automatically)
    <buffer>
      @type file
      path /fluentd/buffer/es
      flush_interval 5s
      retry_max_interval 30
      chunk_limit_size 8m
      flush_thread_count 2
    </buffer>
  </match>

# Wire config to values via env so you can tweak host/port/scheme without editing the config block
extraEnvVars:
  - name: elasticsearch_host
    value: "{{ .Values.elasticsearch.host }}"
  - name: elasticsearch_port
    value: "{{ .Values.elasticsearch.port | toString }}"
  - name: elasticsearch_scheme
    value: "{{ .Values.elasticsearch.scheme }}"
