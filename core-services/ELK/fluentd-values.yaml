fullnameOverride: fluentd
namespaceOverride: services

daemonset:
  enabled: true

image:
  registry: docker.io
  repository: fluent/fluentd
  tag: v1.16-debian-1
  pullPolicy: IfNotPresent

rbac:
  create: true

serviceAccount:
  create: true
  name: fluentd

# Run as root so we can read node logs; we can harden later if you want
containerSecurityContext:
  enabled: true
  runAsUser: 0
  runAsNonRoot: false

# Mount host logs using chart flags (avoids duplicate volumes)
mountVarLogDirectory: true                 # mounts /var/log
mountDockerContainersDirectory: true       # mounts /var/lib/docker/containers (if present)

# -------- Buffer volume (emptyDir for now to get you running) --------
persistence:
  enabled: false

extraVolumes:
  - name: fluentd-buffer
    emptyDir: {}
  - name: fluentd-plugins
    emptyDir: {}

extraVolumeMounts:
  - name: fluentd-buffer
    mountPath: /fluentd/buffer
  - name: fluentd-plugins
    mountPath: /fluentd/plugins

# Install required plugins in an initContainer into /fluentd/plugins,
# then add that path to Ruby's load path via FLUENTD_OPT.
extraInitContainers:
  - name: install-plugins
    image: docker.io/fluent/fluentd:v1.16-debian-1
    imagePullPolicy: IfNotPresent
    command: ["/bin/sh","-lc"]
    args:
      - >
        gem install --no-document
        fluent-plugin-elasticsearch
        fluent-plugin-prometheus
        fluent-plugin-kubernetes_metadata_filter
        --install-dir /fluentd/plugins &&
        echo "Plugins installed to /fluentd/plugins"
    volumeMounts:
      - name: fluentd-plugins
        mountPath: /fluentd/plugins

extraEnvVars:
  - name: FLUENTD_CONF
    value: fluent.conf
  - name: FLUENTD_OPT
    value: "-I /fluentd/plugins"

# Expose metrics service & ServiceMonitor; probes will work once Fluentd starts
metrics:
  serviceMonitor:
    enabled: true
    namespace: services
    interval: 30s
    scrapeTimeout: 10s
    endpoints:
      - port: metrics
        path: /metrics
        interval: 15s
        scrapeTimeout: 10s

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 250m
    memory: 256Mi

# Keep your ES connection values; the config below reads them via env
elasticsearch:
  enabled: true
  host: elasticsearch-master
  port: 9200
  scheme: https
  # If you need auth/CA later, we can add user/password and mount a CA secret.

# Fluentd config:
#  - tail /var/log/containers
#  - kubernetes metadata
#  - prometheus metrics on :24231/metrics
#  - elasticsearch output with PVC-backed (here emptyDir) file buffer
configFile: |-
  <source>
    @type tail
    @id in_kube_logs
    path /var/log/containers/*.log
    pos_file /fluentd/log/k8s-containers.pos
    tag kube.*
    <parse>
      @type regexp
      expression /^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<message>.*)$/
      time_format %Y-%m-%dT%H:%M:%S.%N%:z
    </parse>
    read_from_head true
    refresh_interval 5
    rotate_wait 5
    multiline_flush_interval 5
  </source>

  <filter kube.**>
    @type kubernetes_metadata
    @id filter_kube_metadata
    skip_labels false
    skip_container_metadata false
    skip_namespace_metadata false
    skip_master_url true
  </filter>

  <source>
    @type prometheus
    bind 0.0.0.0
    port 24231
  </source>
  <source>
    @type prometheus_monitor
  </source>

  <match kube.**>
    @type elasticsearch
    @id out_es
    host ${elasticsearch_host}
    port ${elasticsearch_port}
    scheme ${elasticsearch_scheme}
    logstash_format true
    include_tag_key true
    reconnect_on_error true
    reload_connections true
    request_timeout 60s
    # ssl_verify true
    # ca_file ${elasticsearch_ca_file}
    # user ${elasticsearch_user}
    # password ${elasticsearch_password}

    <buffer>
      @type file
      path /fluentd/buffer/es
      flush_interval 5s
      retry_max_interval 30
      chunk_limit_size 8m
      flush_thread_count 2
    </buffer>
  </match>

# Wire ES settings into env for the config to consume
extraEnvVars:
  - name: elasticsearch_host
    value: "{{ .Values.elasticsearch.host }}"
  - name: elasticsearch_port
    value: "{{ .Values.elasticsearch.port | toString }}"
  - name: elasticsearch_scheme
    value: "{{ .Values.elasticsearch.scheme }}"
